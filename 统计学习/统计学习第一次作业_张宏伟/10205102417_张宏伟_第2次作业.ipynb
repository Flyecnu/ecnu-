{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import math\n",
    "import re\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "取鸾尾花数据的两个特征维度展示"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7fb6b59a5dd0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "with open('iris.txt','r') as f:\n",
    "    trainset = []\n",
    "    for train_line in f:\n",
    "      train_line = train_line.strip()\n",
    "      train_L = re.split(',|;|\\t| ',train_line)\n",
    "      trainset.append([float(x) for x in train_L[:-1]])\n",
    "    # print (trainset[:50])\n",
    "x0 = np.array(trainset[:50])\n",
    "x1 = np.array(trainset[50:100])\n",
    "x2 = np.array(trainset[100:150])\n",
    "# print(x0[:,0])\n",
    "plt.scatter(x0[:,0],x0[:,1],c='r',marker='o',label='setosa(山鸢尾)')\n",
    "plt.scatter(x1[:,0],x1[:,1],c='g',marker='+',label='virgincia(维吉尼亚鸢尾)')\n",
    "plt.scatter(x2[:,0],x2[:,1],c='blue',marker='x',label='versicolor(变色鸢尾)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SVM_parameter用于存储SVM需要用到的参数\n",
    "class SVM_parameter():\n",
    "  def __init__(self,trainset,trainlabel,C,toler,kernel_type,sigma):\n",
    "    self.trainset = trainset\n",
    "    self.trainlabel = trainlabel\n",
    "    self.N = len(trainset)#样本个数\n",
    "    self.d = len(trainset[0])#特征个数\n",
    "    self.C = C\n",
    "    self.alph = [0.]*self.N#\n",
    "    self.b = 0.\n",
    "    self.error_cache = [0.]*self.N#N维的list存储deltaE\n",
    "    self.toler =toler\n",
    "    self.two_sigma_squared= 2*sigma**2\n",
    "    self.kernel = kernel_type\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "多分类代码的思路是先完成第一个类和其余类的二分类问题，再完成第二个类和其余类的二分类问题\n",
    "依次进行，这样就可以完成所有类的分类问题了。\n",
    "训练SVM，要求：输入训练集数据，以及C（惩罚参数，默认为1），toler精确度（默认为1），kernel_type（核函数，可以选择高斯核:\"rbf\"与线性核:\"linear\"），sigma(kernel_type 为高斯核)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_SVM(train_file_name,C=1.0,toler=0.001,kernel_type=\"linear\",sigma=0.5):\n",
    "  with open(train_file_name,'r') as f:\n",
    "    trainset = []\n",
    "    raw_train_labels_L1 = []#所有样本原始训练标签，用于计数\n",
    "    raw_train_labels_L2 = []#原始训练标签种类（即几分类），用于循环\n",
    "    for train_line in f:\n",
    "      train_line = train_line.strip()\n",
    "      train_L = re.split(',|;|\\t| ',train_line)\n",
    "      trainset.append([float(x) for x in train_L[:-1]])\n",
    "      if train_L[-1] not in raw_train_labels_L2:#获取标签种类，以及对应标签的数目\n",
    "        raw_train_labels_L1.append(train_L[-1])\n",
    "        raw_train_labels_L2.append(train_L[-1]) \n",
    "      else:\n",
    "        raw_train_labels_L1.append(train_L[-1])\n",
    "    print (raw_train_labels_L1,raw_train_labels_L2)\n",
    "  #循环分类的次数为标签种类数\n",
    "  if len(raw_train_labels_L2) == 2:#如果分类标签个数是二，直接二分类就行\n",
    "    trainlabel = []\n",
    "    for i in raw_train_labels_L1:#输入标签\n",
    "      if i == raw_train_labels_L1[0]:\n",
    "        trainlabel.append(1)\n",
    "      else:\n",
    "        trainlabel.append(-1)\n",
    "        \n",
    "    svm = SVM_parameter(trainset,trainlabel,C,toler,kernel_type,sigma)#获取参数\n",
    "    MainRoutine(svm)#调用SMO算法主函数\n",
    "    classifier = svm#二分类分类器直接为SVM类  \n",
    "  else:#多分类\n",
    "    classifier = []\n",
    "    for sample1 in raw_train_labels_L2:#循环，每个类别单独拿出来和其余类别进行二分类\n",
    "      trainlabel = []    \n",
    "      for element in raw_train_labels_L1:#第一个分类的标签设为1，其余类别的标签设为-1，以此类推\n",
    "          if element == sample1:\n",
    "            trainlabel.append(1)\n",
    "          else:\n",
    "            trainlabel.append(-1)\n",
    "      #多分类下进行二分类\n",
    "      svm = SVM_parameter(trainset,trainlabel,C,toler,kernel_type,sigma)  \n",
    "      MainRoutine(svm)\n",
    "      classifier.append(svm)#多分类分类器存储在列表中\n",
    "  return classifier#训练集返回训练的分类器\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_SVM(test_file_name,classifier):\n",
    "  with open(test_file_name,'r') as f:\n",
    "    global testset\n",
    "    testset = []\n",
    "    raw_test_labels_L1 = []#原始测试标签\n",
    "    raw_test_labels_L2 = []#\n",
    "    for test_line in f:\n",
    "      test_line = test_line.strip()\n",
    "      test_L = re.split(',|;|\\t| ',test_line)\n",
    "      testset.append([float(x) for x in test_L[:-1]])\n",
    "      if test_L[-1] not in raw_test_labels_L2:#获取标签种类，以及对应标签的数目\n",
    "        raw_test_labels_L1.append(test_L[-1])\n",
    "        raw_test_labels_L2.append(test_L[-1])\n",
    "      else:\n",
    "        raw_test_labels_L1.append(test_L[-1])\n",
    "\n",
    "  if len(raw_test_labels_L2) == 2:#如果分类标签个数是二，直接可以使用测试数据\n",
    "    testlabel = []\n",
    "    for i in raw_test_labels_L1:#输入标签\n",
    "      if i == raw_test_labels_L1[0]:\n",
    "        testlabel.append(1)\n",
    "      else:\n",
    "        testlabel.append(-1)\n",
    "    rate = accuracy(classifier,testset,testlabel)\n",
    "    \n",
    "  else:#多分类测试\n",
    "    #循环，每个输入样本用训练好的所有分类器去分类，得分最高（即分类效果最好）的为相应的分类结果\n",
    "    right_count = 0\n",
    "    for sample in testset:\n",
    "      sample_label = 1\n",
    "      #对于每一类样本来说，都有其对应的召回率和精确率。\n",
    "      #多个训练器获取最优的训练器和正确率      \n",
    "      max_output = 0 #获取得分最高的分数\n",
    "      for i in range(len(classifier)):\n",
    "        output = learned_func(classifier[i],testset.index(sample),is_test=1)\n",
    "        if output > max_output:\n",
    "          max_output = output\n",
    "        else:\n",
    "          continue\n",
    "      if max_output*sample_label >= 0.0:#如果得分最高的分数大于0，则认为分类正确\n",
    "        right_count += 1\n",
    "    rate = 100.0*right_count/len(raw_test_labels_L1)\n",
    "  return rate\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def learned_func(svm,k,is_test = 0):\n",
    "  w_x = 0.\n",
    "  for i in range(svm.N):\n",
    "    if svm.alph[i] > 0:\n",
    "      ################################################################################\n",
    "      # TODO:             写出 w*x                                                    #\n",
    "      ################################################################################\n",
    "      # *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "\n",
    "      w_x+=svm.alph[i]*svm.trainlabel[i]*kernel_func(svm,i,k,is_test)\n",
    "\n",
    "\n",
    "      # *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "  v = w_x - svm.b   ###目标函数：wx-b\n",
    "  return v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dot_product_func(svm,i1,i2,is_test = 0):#计算两个样本的点积\n",
    "    dot = 0.\n",
    "    if is_test == 0:    #训练\n",
    "        for i in range(svm.d):\n",
    "            dot += svm.trainset[i1][i]*svm.trainset[i2][i]\n",
    "    ################################################################################\n",
    "    # TODO:            一共有三种情况，写出剩下两种if                                   #\n",
    "    ################################################################################\n",
    "    # *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "    elif is_test !=0 and i1!= i2: ##考虑 testset[i2]\n",
    "        for i in range(svm.d):\n",
    "            #pass\n",
    "            dot+=svm.trainset[i1][i]*testset[i2][i]\n",
    "    else:\n",
    "        for i in range(svm.d): ## 考虑 testset\n",
    "            #pass\n",
    "            dot+=testset[i1][i]*testset[i2][i]  \n",
    "    # *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "    return dot\n",
    "\n",
    "def rbf(svm,s):\n",
    "    ################################################################################\n",
    "    # TODO:            参考math.exp库函数，补全kernel_func函数高斯核函数计算方法         #\n",
    "    ################################################################################\n",
    "    # *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "\n",
    "    #pass\n",
    "    s=math.exp(-s/svm.two_sigma_squared)  #e^(-(x-z)^2/(2*sigma^2))\n",
    "\n",
    "    # *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "    return s\n",
    "\n",
    "def kernel_func(svm,i1,i2,is_test = 0):\n",
    "    def linear_kernel(svm,i1,i2):#线性核\n",
    "        s = dot_product_func(svm,i1,i2)\n",
    "        return s\n",
    "\n",
    "    def rbf_kernel(svm,i1,i2):#高斯核 \n",
    "        # 需要考虑i1和i2是训练还是测试，分别考虑\n",
    "        s = dot_product_func(svm,i1,i1,is_test = 0) + dot_product_func(svm,i2,i2,is_test = is_test) - 2*dot_product_func(svm,i1,i2,is_test = is_test)\n",
    "        s = rbf(svm,s)\n",
    "        return s\n",
    "  \n",
    "    if svm.kernel == 'linear':\n",
    "        kernel_func = linear_kernel\n",
    "    elif svm.kernel == 'rbf':\n",
    "        kernel_func = rbf_kernel   \n",
    "    return kernel_func(svm,i1,i2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def takeStep(svm,i1,i2):\n",
    "  \n",
    "    '''\n",
    "    进行更新优化\n",
    "    优化两个拉格朗日乘子，如果优化成功返回1，否则返回0\n",
    "    '''\n",
    "    if i1 == i2:#选取不同的样本点\n",
    "        return 0    \n",
    "  \n",
    "    alph1 = svm.alph[i1]#获取α、trainlabel数据\n",
    "    y1 = svm.trainlabel[i1]\n",
    "\n",
    "    if alph1 > 0 and alph1 < svm.C:\n",
    "        E1 = svm.error_cache[i1]\n",
    "    else:\n",
    "        ################################################################################\n",
    "        # TODO:          定义另一种情况的E1，采用前面的learned_func函数                     #\n",
    "        ################################################################################\n",
    "        # *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "\n",
    "        #pass\n",
    "        E1=learned_func(svm,i1)-y1\n",
    "        # *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "\n",
    "    alph2 = svm.alph[i2]\n",
    "    y2 = svm.trainlabel[i2]\n",
    "\n",
    "    if alph2 > 0 and alph2 < svm.C:\n",
    "        E2 = svm.error_cache[i2]\n",
    "    else:\n",
    "        ################################################################################\n",
    "        # TODO:                     定义E2                                             #\n",
    "        ################################################################################\n",
    "        # *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "\n",
    "        #pass\n",
    "        E2=learned_func(svm,i2)-y2\n",
    "\n",
    "        # *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "  \n",
    "    s = y1*y2\n",
    "    if y1 != y2:\n",
    "        L = max(0.,-(alph1 - alph2))\n",
    "        ################################################################################\n",
    "        # TODO:                     定义边界H                                             #\n",
    "        ################################################################################\n",
    "        # *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "    \n",
    "        #pass\n",
    "        H=min(svm.C,svm.C+alph2-alph1)\n",
    "\n",
    "        # *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "  \n",
    "    elif y1 == y2:\n",
    "    ################################################################################\n",
    "    # TODO:                     定边界L、H                                          #\n",
    "    ################################################################################\n",
    "    # *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "    \n",
    "        #pass\n",
    "        L=max(0,alph1+alph2-svm.C)\n",
    "        H=min(svm.C,alph2+alph1)\n",
    "\n",
    "    # *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "    \n",
    "    if L == H:\n",
    "         return 0\n",
    "  \n",
    "    k11 = kernel_func(svm,i1,i1)\n",
    "    k12 = kernel_func(svm,i1,i2)\n",
    "    k22 = kernel_func(svm,i2,i2)\n",
    "  ################################################################################\n",
    "  # TODO:                     定义eta，即η=2k12-k11-k22                           #\n",
    "  ################################################################################\n",
    "  # *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "\n",
    "    #pass\n",
    "    eta=2*k12-k11-k22\n",
    "  \n",
    "  # *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "  \n",
    "\n",
    "    if eta < 0: #η<0，目标函数为凹函数，有极小值，更新α\n",
    "    ################################################################################\n",
    "    # TODO:                     更新a2，即alph2_new                                 #\n",
    "    ################################################################################\n",
    "    # *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "\n",
    "        #pass\n",
    "        a2=alph2+y2*(E2-E1)/eta\n",
    "    \n",
    "    # *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "\n",
    "        #检查α是否在可行域，如果不在，对α进行剪切\n",
    "        if a2 < L: #如果α小于最小值，取可行域的最小值\n",
    "            a2 = L\n",
    "        elif a2 > H: #如果α大于最大值，取可行域的最大值\n",
    "            a2 = H \n",
    "\n",
    "    else:#当有其他情况时，如η= 0，目标函数为线性最小值在边缘取到，更新α\n",
    "        #计算对应边缘点(a2 = L,a2 = H) 的目标函数值\n",
    "        Lobj = 0.5*eta*(L**2)+(1.0*y2*(E1-E2)-eta*alph2)*L\n",
    "        Hobj = 0.5*eta*(H**2)+(1.0*y2*(E1-E2)-eta*alph2)*H\n",
    "        #比较Lobj和Hobj,取较大的函数值(这里大于的定义是大于eps精度时)\n",
    "        if Lobj > Hobj:\n",
    "            a2 = L\n",
    "        elif Lobj < Hobj:\n",
    "            a2 = H\n",
    "        else:#当两者的value值之差在eps之内时，认为α没有发生变化，如果α差值太小，则迭代下一步\n",
    "            return 0\n",
    "  \n",
    "  \n",
    "  ################################################################################\n",
    "  # TODO: 如果a2和alph2的值差别较大，则认为这次的迭代是有效的,更新a1                     #\n",
    "  ################################################################################\n",
    "  # *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "\n",
    "    #pass\n",
    "    a1=alph1+s*(alph2-a2)\n",
    "\n",
    "  # *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "\n",
    "    '''\n",
    "    如果a1小于0，则使得a1=0，同时调整a2满足约束条件\n",
    "    如果a1大于C，则使得a1=svm.C，同时调整a2满足约束条件\n",
    "    '''\n",
    "  \n",
    "    if a1 < 0:\n",
    "        a2 += s*a1\n",
    "        a1 = 0.0\n",
    "    elif a1 > svm.C:\n",
    "        t = a1 - svm.C\n",
    "        a2 += s*t\n",
    "        a1 = svm.C\n",
    "  \n",
    "  \n",
    "    #b_new\n",
    "    #通过E1更新bnew\n",
    "    if a1 > 0 and a1 < svm.C:\n",
    "        bnew = svm.b + E1 + y1*(a1-alph1)*k11 + y2*(a2-alph2)*k12\n",
    "    else:\n",
    "        if a2 > 0 and a2 < svm.C:\n",
    "      ################################################################################\n",
    "      # TODO:    update b according to E2 or update b by averaging the above results #  \n",
    "      #                            在两个pass处修改添加代码                             #\n",
    "      ################################################################################\n",
    "      # *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "\n",
    "            #pass\n",
    "            bnew = svm.b + E2 + y1*(a1-alph1)*k12 + y2*(a2-alph2)*k22\n",
    "\n",
    "        else:\n",
    "            \n",
    "            #pass\n",
    "            b1new = svm.b + E1 + y1*(a1-alph1)*k11 + y2*(a2-alph2)*k12\n",
    "            b2new = svm.b + E2 + y1*(a1-alph1)*k12 + y2*(a2-alph2)*k22\n",
    "            bnew=(b1new+b2new)/2\n",
    "            \n",
    "      \n",
    "      # *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "    delta_b = bnew - svm.b\n",
    "    svm.b = bnew\n",
    "\n",
    "    #更新error cache\n",
    "    t1 = y1*(a1-alph1)\n",
    "    t2 = y2*(a2-alph2)\n",
    "\n",
    "    for i in range(svm.N):\n",
    "        if 0 < svm.alph[i] and svm.alph[i] < svm.C:    \n",
    "            svm.error_cache[i] += t1*kernel_func(svm,i1,i)+ t2*kernel_func(svm,i2,i) - delta_b\n",
    "    svm.error_cache[i1] = 0.\n",
    "    svm.error_cache[i2] = 0.\n",
    "  \n",
    "    #更新α\n",
    "    svm.alph[i1] = a1\n",
    "    svm.alph[i2] = a2\n",
    "  \n",
    "    #优化成功\n",
    "    return 1\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def examineExample(svm,i1):\n",
    "  y1 = svm.trainlabel[i1]\n",
    "  alph1 = svm.alph[i1]\n",
    "  if alph1 > 0 and alph1 < svm.C:#若α在可行域内\n",
    "    E1 = svm.error_cache[i1]\n",
    "  else:\n",
    "    E1 = learned_func(svm,i1) - y1\n",
    "  r1 = y1*E1\n",
    "  '''\n",
    "  判断第一个α是否违背KKT条件，违背程度为tolerance\n",
    "  若违背KKT条件，用以下三种方式选择第二个α\n",
    "  第一种：在非边界样本中选取最大的|E1-E2|\n",
    "  第二种：在非边界样本中随机选取一个\n",
    "  第三种：在整个样本中随机选取一个\n",
    "  '''\n",
    "  if r1 < -svm.toler and alph1 < svm.C or r1 > svm.toler and alph1 > 0:\n",
    "    i2 = -1\n",
    "    tmax = 0\n",
    "    for k in range(svm.N):#先在非边界的点（支持向量）中选取dealtE最大的a2\n",
    "      if svm.alph[k] > 0 and svm.alph[k] < svm.C:#非边界点条件\n",
    "        E2 = svm.error_cache[k]\n",
    "        temp = abs(E1-E2)\n",
    "        if temp > tmax:\n",
    "          tmax = temp\n",
    "          i2 = k\n",
    "    if i2 >= 0:\n",
    "      if takeStep(svm,i1,i2):\n",
    "        return 1\n",
    "    \n",
    "    #如果最大的deltaE对应的α优化失败，从非边界点中随机寻找进行优化\n",
    "    for k in range(random.randint(0,svm.N),svm.N):\n",
    "      i2 = k % svm.N\n",
    "      if svm.alph[i2] > 0 and svm.alph[i2] < svm.C:#非边界点条件\n",
    "        if takeStep(svm,i1,i2):\n",
    "            return 1\n",
    "\n",
    "    #如果非边界点全都优化失败，从整个训练集里寻找优化\n",
    "    for k in range(random.randint(0,svm.N),svm.N):\n",
    "      i2 = k % svm.N\n",
    "      if takeStep(svm,i1,i2):\n",
    "        return 1    \n",
    "  return 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MainRoutine(svm):\n",
    "  numChanged = 0\n",
    "  examineAll = 1\n",
    "  count_while = 0\n",
    "  while numChanged > 0 or examineAll:\n",
    "    count_while += 1\n",
    "    numChanged = 0\n",
    "    if examineAll:\n",
    "      count_all = 0\n",
    "      for k in range(svm.N):\n",
    "        count_all += 1\n",
    "        numChanged += examineExample(svm,k)\n",
    "    else:\n",
    "      count_no_boundary = 0\n",
    "      for k in range(svm.N):\n",
    "        if svm.alph[k] != 0 and svm.alph[k] != svm.C:\n",
    "          count_no_boundary += 1\n",
    "          numChanged += examineExample(svm,k)\n",
    "    if examineAll == 1:\n",
    "      examineAll = 0\n",
    "    elif numChanged == 0:\n",
    "      examineAll = 1\n",
    "  return svm.alph,svm.b,svm.error_cache\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(svm,testset,testlabel):\n",
    "  #这个accuracy只用来计算二分类的准确率，对于多分类，没有准确率一说，因为多分类的正负样本并不明确\n",
    "  TP = 0\n",
    "  FP = 0\n",
    "  FN = 0\n",
    "  TN = 0\n",
    "  for i in range(len(testset)):\n",
    "    if learned_func(svm,i,is_test = 1) >= 0.0:\n",
    "      if testlabel[i] == 1:\n",
    "        TP += 1\n",
    "      else:\n",
    "        FP += 1\n",
    "    elif learned_func(svm,i,is_test = 1) <= -0.0:\n",
    "      if testlabel[i] == -1:\n",
    "        TN += 1\n",
    "      else:\n",
    "        FN += 1 \n",
    "  print ('TP,FP,FN,TN:',TP,FP,FN,TN)\n",
    "  precision = 100.0*TP/(TP+FP)\n",
    "  recall = 100.0*TP/(TP+FN)\n",
    "  accuracy = 100.0*(TP+TN)/(TP+TN+FP+FN)\n",
    "  return precision,recall,accuracy\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "主代码，定义分类器和展示准确率，能写完的话效果应该是不错的。\n",
    "同学们可以自己定义分类器，这里是示例，同时可以选择一些参数，比如高斯核、线性核等。\n",
    "对于TP，FP等评估指标同学感兴趣可以画图看看。\n",
    "这次作用重点在于SMO算法求解SVM问题的步骤过程"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Iris-setosa', 'Iris-setosa', 'Iris-setosa', 'Iris-setosa', 'Iris-setosa', 'Iris-setosa', 'Iris-setosa', 'Iris-setosa', 'Iris-setosa', 'Iris-setosa', 'Iris-setosa', 'Iris-setosa', 'Iris-setosa', 'Iris-setosa', 'Iris-setosa', 'Iris-setosa', 'Iris-setosa', 'Iris-setosa', 'Iris-setosa', 'Iris-setosa', 'Iris-setosa', 'Iris-setosa', 'Iris-setosa', 'Iris-setosa', 'Iris-setosa', 'Iris-versicolor', 'Iris-versicolor', 'Iris-versicolor', 'Iris-versicolor', 'Iris-versicolor', 'Iris-versicolor', 'Iris-versicolor', 'Iris-versicolor', 'Iris-versicolor', 'Iris-versicolor', 'Iris-versicolor', 'Iris-versicolor', 'Iris-versicolor', 'Iris-versicolor', 'Iris-versicolor', 'Iris-versicolor', 'Iris-versicolor', 'Iris-versicolor', 'Iris-versicolor', 'Iris-versicolor', 'Iris-versicolor', 'Iris-versicolor', 'Iris-versicolor', 'Iris-versicolor', 'Iris-versicolor'] ['Iris-setosa', 'Iris-versicolor']\n",
      "TP,FP,FN,TN: 25 0 0 25\n",
      "(100.0, 100.0, 100.0)\n",
      "['Iris-setosa', 'Iris-setosa', 'Iris-setosa', 'Iris-setosa', 'Iris-setosa', 'Iris-setosa', 'Iris-setosa', 'Iris-setosa', 'Iris-setosa', 'Iris-setosa', 'Iris-setosa', 'Iris-setosa', 'Iris-setosa', 'Iris-setosa', 'Iris-setosa', 'Iris-setosa', 'Iris-setosa', 'Iris-setosa', 'Iris-setosa', 'Iris-setosa', 'Iris-setosa', 'Iris-setosa', 'Iris-setosa', 'Iris-setosa', 'Iris-setosa', 'Iris-versicolor', 'Iris-versicolor', 'Iris-versicolor', 'Iris-versicolor', 'Iris-versicolor', 'Iris-versicolor', 'Iris-versicolor', 'Iris-versicolor', 'Iris-versicolor', 'Iris-versicolor', 'Iris-versicolor', 'Iris-versicolor', 'Iris-versicolor', 'Iris-versicolor', 'Iris-versicolor', 'Iris-versicolor', 'Iris-versicolor', 'Iris-versicolor', 'Iris-versicolor', 'Iris-versicolor', 'Iris-versicolor', 'Iris-versicolor', 'Iris-versicolor', 'Iris-versicolor', 'Iris-versicolor', 'Iris-virginica', 'Iris-virginica', 'Iris-virginica', 'Iris-virginica', 'Iris-virginica', 'Iris-virginica', 'Iris-virginica', 'Iris-virginica', 'Iris-virginica', 'Iris-virginica', 'Iris-virginica', 'Iris-virginica', 'Iris-virginica', 'Iris-virginica', 'Iris-virginica', 'Iris-virginica', 'Iris-virginica', 'Iris-virginica', 'Iris-virginica', 'Iris-virginica', 'Iris-virginica', 'Iris-virginica', 'Iris-virginica', 'Iris-virginica', 'Iris-virginica'] ['Iris-setosa', 'Iris-versicolor', 'Iris-virginica']\n",
      "100.0\n"
     ]
    }
   ],
   "source": [
    "bi_train = train_SVM(\"iris_train_set_bi.txt\",kernel_type=\"rbf\")\n",
    "bi_test = test_SVM(\"iris_test_set_bi.txt\",bi_train)\n",
    "print(bi_test)\n",
    "\n",
    "mu_train = train_SVM(\"iris_train_set_multi.txt\",kernel_type=\"rbf\")\n",
    "mu_test = test_SVM(\"iris_test_set_multi.txt\",mu_train)\n",
    "print(mu_test)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e1315e6714f2518a6216a6eec3b047587d10875bf19b853b35d3e5c84c569e2a"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('torch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
