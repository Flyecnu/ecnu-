{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using skLearn decisionTree Classifier\n",
      "loading data...\n",
      "data is loaded...\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "coauthor_1\n",
      "coauthor_2\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "make train feature file ...\n",
      "make test feature file ...\n",
      "==> Train the model ...\n",
      "==> Test the model ...\n"
     ]
    }
   ],
   "source": [
    "#encoding: utf-8\n",
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "import json\n",
    "import pandas\n",
    "from model_trainer.evalution import get_prediction, Evalution\n",
    "from model_trainer.data_loader import load_train_data\n",
    "from model_trainer.data_loader import load_test_data\n",
    "from model_trainer.make_feature_file import Make_feature_file\n",
    "from feature_functions import *\n",
    "from classifier import *\n",
    "\n",
    "\n",
    "class Trainer(object):\n",
    "    def __init__(self,\n",
    "                classifier,\n",
    "                model_path,\n",
    "                feature_function_list,\n",
    "                train_feature_path,\n",
    "                test_feature_path,\n",
    "                test_result_path):\n",
    "\n",
    "        self.classifier = classifier\n",
    "        self.model_path = model_path\n",
    "        self.feature_function_list = feature_function_list\n",
    "        self.train_feature_path = train_feature_path\n",
    "        self.test_feature_path = test_feature_path\n",
    "        self.test_result_path = test_result_path\n",
    "\n",
    "\n",
    "    def make_feature_file(self, train_AuthorIdPaperIds, test_AuthorIdPaperIds, dict_coauthor, dict_paperIdAuthorId_to_name_aff, PaperAuthor, Author):\n",
    "\n",
    "        print((\"-\"*120))\n",
    "        print((\"\\n\".join([f.__name__ for f in feature_function_list])))\n",
    "        print((\"-\" * 120))\n",
    "\n",
    "        print(\"make train feature file ...\")\n",
    "        Make_feature_file(train_AuthorIdPaperIds, dict_coauthor, dict_paperIdAuthorId_to_name_aff, PaperAuthor, Author, self.feature_function_list, self.train_feature_path)\n",
    "        print(\"make test feature file ...\")\n",
    "        Make_feature_file(test_AuthorIdPaperIds, dict_coauthor, dict_paperIdAuthorId_to_name_aff, PaperAuthor, Author, self.feature_function_list, self.test_feature_path)\n",
    "\n",
    "\n",
    "    def train_mode(self):\n",
    "        self.classifier.train_model(self.train_feature_path, self.model_path)\n",
    "\n",
    "    def test_model(self):\n",
    "        self.classifier.test_model(self.test_feature_path, self.model_path, self.test_result_path)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "\n",
    "    ''' 特征函数列表 '''\n",
    "    feature_function_list = [\n",
    "        coauthor_1,\n",
    "        coauthor_2,\n",
    "        # stringDistance_1,\n",
    "        # stringDistance_2,\n",
    "    ]\n",
    "\n",
    "    ''' 分类器 '''\n",
    "    # 决策树，NB，等\n",
    "    classifier = Classifier(skLearn_DecisionTree())\n",
    "    # classifier = Classifier(skLearn_NaiveBayes())\n",
    "    # classifier = Classifier(skLearn_svm())\n",
    "    # classifier = Classifier(skLearn_lr())\n",
    "    # classifier = Classifier(skLearn_KNN())\n",
    "    # classifier = Classifier(sklearn_RandomForestClassifier())\n",
    "    # classifier = Classifier(skLearn_AdaBoostClassifier())\n",
    "    # classifier = Classifier(sklearn_VotingClassifier())\n",
    "\n",
    "    ''' model path '''\n",
    "    model_path = config.MODEL_PATH\n",
    "\n",
    "    ''' train feature_file & test feature_file & test result path '''\n",
    "    train_feature_path = config.TRAIN_FEATURE_PATH\n",
    "    test_feature_path = config.TEST_FEATURE_PATH\n",
    "    test_result_path = config.TEST_RESULT_PATH\n",
    "\n",
    "    ''' Trainer '''\n",
    "    trainer = Trainer(classifier, model_path, feature_function_list, train_feature_path, test_feature_path, test_result_path)\n",
    "\n",
    "    ''' load data '''\n",
    "    print(\"loading data...\")\n",
    "    train_AuthorIdPaperIds = load_train_data(config.TRAIN_FILE)  # 加载训练数据\n",
    "    test_AuthorIdPaperIds = load_test_data(config.TEST_FILE)  # 加载测试数据\n",
    "    # coauthor, 共作者数据\n",
    "    dict_coauthor = json.load(open(config.COAUTHOR_FILE), encoding=\"utf-8\")\n",
    "    # (paperId, AuthorId) --> {\"name\": \"name1##name2\", \"affiliation\": \"aff1##aff2\"}\n",
    "    dict_paperIdAuthorId_to_name_aff \\\n",
    "        = json.load(open(config.PAPERIDAUTHORID_TO_NAME_AND_AFFILIATION_FILE), encoding=\"utf-8\")\n",
    "    # 使用pandas加载csv数据\n",
    "    PaperAuthor = pandas.read_csv(config.PAPERAUTHOR_FILE)  # 加载 PaperAuthor.csv 数据\n",
    "    Author = pandas.read_csv(config.AUTHOR_FILE) # 加载 Author.csv 数据\n",
    "    print(\"data is loaded...\")\n",
    "\n",
    "    # 为训练和测试数据，抽取特征，分别生成特征文件\n",
    "    trainer.make_feature_file(train_AuthorIdPaperIds, test_AuthorIdPaperIds, dict_coauthor, dict_paperIdAuthorId_to_name_aff, PaperAuthor, Author)\n",
    "    # 根据训练特征文件，训练模型\n",
    "    trainer.train_mode()\n",
    "    # 使用训练好的模型，对测试集进行预测\n",
    "    trainer.test_model()\n",
    "    # 对模型的预测结果，重新进行整理，得到想要的格式的预测结果\n",
    "    get_prediction(config.TEST_FEATURE_PATH, config.TEST_RESULT_PATH, config.TEST_PREDICT_PATH)\n",
    "\n",
    "    ''' 评估,（预测 vs 标准答案）'''\n",
    "    gold_file = config.GOLD_FILE\n",
    "    pred_file = config.TEST_PREDICT_PATH\n",
    "    cmd = \"python evalution.py %s %s\" % (gold_file, pred_file)\n",
    "    os.system(cmd)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "########################################\n",
      "    评估结果, 以Accuracy为准\n",
      "########################################\n",
      "\n",
      "准确率: 74.65%\n",
      "row = predicted, column = truth\n",
      "  0     1      \n",
      "0 426.0 266.0  \n",
      "1 319.0 1297.0 \n",
      "\n",
      "0 \tprecision 0.615607 \trecall 0.571812\t F1 0.592902\n",
      "1 \tprecision 0.802599 \trecall 0.829814\t F1 0.815980\n",
      "* Overall accuracy rate = 0.746534\n",
      "* Average precision 0.709103 \t recall 0.700813\t F1 0.704441\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "#encoding: utf-8\n",
    "import os\n",
    "import sys\n",
    "import importlib\n",
    "importlib.reload(sys)\n",
    "# sys.setdefaultencoding('utf-8')\n",
    "sys.path.append(\"../\")\n",
    "import util\n",
    "import config\n",
    "from confusion_matrix import Alphabet, ConfusionMatrix\n",
    "\n",
    "\n",
    "# 对模型的预测结果，重新进行整理，得到想要的格式的预测结果\n",
    "def get_prediction(test_feature_path, test_result_path, to_file):\n",
    "    feature_list = [line.strip() for line in open(test_feature_path)]\n",
    "    predict_list = [line.strip() for line in open(test_result_path)]\n",
    "\n",
    "    dict_authorId_to_predict = {}\n",
    "    for feature, predict in zip(feature_list, predict_list):\n",
    "        paperId, authorId = feature.split(\" # \")[-1].split(\" \")\n",
    "        paperId = int(paperId)\n",
    "        authorId = int(authorId)\n",
    "\n",
    "        if authorId not in dict_authorId_to_predict:\n",
    "            dict_authorId_to_predict[authorId] = {}\n",
    "            dict_authorId_to_predict[authorId][\"ConfirmedPaperIds\"] = []\n",
    "            dict_authorId_to_predict[authorId][\"DeletedPaperIds\"] = []\n",
    "\n",
    "        if predict == \"1\":\n",
    "            dict_authorId_to_predict[authorId][\"ConfirmedPaperIds\"].append(paperId)\n",
    "        if predict == \"0\":\n",
    "            dict_authorId_to_predict[authorId][\"DeletedPaperIds\"].append(paperId)\n",
    "\n",
    "    # to csv\n",
    "    items = sorted(list(dict_authorId_to_predict.items()), key=lambda x: x[0])\n",
    "\n",
    "    data = []\n",
    "    for item in items:\n",
    "        AuthorId = item[0]\n",
    "        ConfirmedPaperIds = \" \".join(map(str, item[1][\"ConfirmedPaperIds\"]))\n",
    "        DeletedPaperIds = \" \".join(map(str, item[1][\"DeletedPaperIds\"]))\n",
    "\n",
    "        data.append({\"AuthorId\": AuthorId, \"ConfirmedPaperIds\": ConfirmedPaperIds, \"DeletedPaperIds\": DeletedPaperIds})\n",
    "\n",
    "    util.write_dict_to_csv([\"AuthorId\", \"ConfirmedPaperIds\", \"DeletedPaperIds\"], data, to_file)\n",
    "\n",
    "\n",
    "# 评估。（预测 vs 标准答案）\n",
    "def Evalution(gold_file_path, pred_file_path):\n",
    "    gold_authorIdPaperId_to_label = {}\n",
    "    pred_authorIdPaperId_to_label = {}\n",
    "\n",
    "    gold_data = util.read_dict_from_csv(gold_file_path)\n",
    "    for item in gold_data:\n",
    "        AuthorId = item[\"AuthorId\"]\n",
    "        # 正样本\n",
    "        for paperId in item[\"ConfirmedPaperIds\"].split(\" \"):\n",
    "            gold_authorIdPaperId_to_label[(AuthorId, paperId)] = \"1\"\n",
    "        # 负样本\n",
    "        for paperId in item[\"DeletedPaperIds\"].split(\" \"):\n",
    "            gold_authorIdPaperId_to_label[(AuthorId, paperId)] = \"0\"\n",
    "\n",
    "    pred_data = util.read_dict_from_csv(pred_file_path)\n",
    "    for item in pred_data:\n",
    "        AuthorId = item[\"AuthorId\"]\n",
    "        # 正样本\n",
    "        for paperId in item[\"ConfirmedPaperIds\"].split(\" \"):\n",
    "            pred_authorIdPaperId_to_label[(AuthorId, paperId)] = \"1\"\n",
    "        # 负样本\n",
    "        for paperId in item[\"DeletedPaperIds\"].split(\" \"):\n",
    "            pred_authorIdPaperId_to_label[(AuthorId, paperId)] = \"0\"\n",
    "\n",
    "    # evaluation\n",
    "    alphabet = Alphabet()\n",
    "    alphabet.add(\"0\")\n",
    "    alphabet.add(\"1\")\n",
    "\n",
    "    cm = ConfusionMatrix(alphabet)\n",
    "    for AuthorId, paperId in gold_authorIdPaperId_to_label:\n",
    "        gold = gold_authorIdPaperId_to_label[(AuthorId, paperId)]\n",
    "        pred = pred_authorIdPaperId_to_label[(AuthorId, paperId)]\n",
    "        cm.add(pred, gold)\n",
    "\n",
    "    return cm\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    gold_file_path = \"/Users/zhanghongwei/Desktop/数据挖掘/kdd/KDD_Benchmark/data/dataset/valid_set/Valid.gold.csv\"\n",
    "    pred_file_path = \"/Users/zhanghongwei/Desktop/数据挖掘/kdd/KDD_Benchmark/predict/test.predict\"\n",
    "\n",
    "\n",
    "    cm = Evalution(gold_file_path, pred_file_path)\n",
    "    # accuracy\n",
    "    acc = cm.get_accuracy()\n",
    "    # 打印评估结果\n",
    "    print(\"\")\n",
    "    print(\"##\" * 20)\n",
    "    print(\"    评估结果, 以Accuracy为准\")\n",
    "    print(\"##\" * 20)\n",
    "    print(\"\")\n",
    "    print(\"准确率: {:.2%}\".format(acc))\n",
    "    cm.print_out()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
